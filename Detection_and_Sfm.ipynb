{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoCiappetta/Features-mapping-using-Two-Frame-Structure-from-motion-and-AI-detection/blob/main/Detection_and_Sfm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dErdEFGLFyP5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meXXso7NPgUi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "\n",
        "#for Ransac\n",
        "from skimage.measure import ransac\n",
        "from skimage.transform import ProjectiveTransform, AffineTransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RS8X_wnhdyeb"
      },
      "outputs": [],
      "source": [
        "#classes used to make the map\n",
        "\n",
        "#feature represents the streetlamps, with their positions and the photos in which they appear\n",
        "class Feature:\n",
        "  def __init__(self, src_image_name, image_corners_coords ,space_coords):\n",
        "    self.images = []#set of the names of image files where this feature is present and where is present in the image\n",
        "    self.images.append((src_image_name, image_corners_coords))\n",
        "    self.space_coords = space_coords #estimate of spatial coordinates of feature (possibly in meters)\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"feature found in {self.images}, likely to be at {self.space_coords}\"\n",
        "\n",
        "  #same feature observed in another image\n",
        "  def add_image(self, new_image_name, image_corners_coords):\n",
        "    if (new_image_name, image_corners_coords) not in self.images:\n",
        "      self.images.append((new_image_name, image_corners_coords))\n",
        "\n",
        "#status represents the images, with the position from which they're taken and the features which appear in them\n",
        "class Status:\n",
        "\n",
        "  def __init__(self, src_image_name, kps, des ,camera_coords, camera_orientation):\n",
        "    self.features = []#from each position there are a number of observable features (always street lamps)\n",
        "    self.image = src_image_name\n",
        "    self.kps = kps\n",
        "    self.des = des\n",
        "    self.camera_coords = camera_coords\n",
        "    #on x,y graph first status always has (0,1) orientation\n",
        "    self.camera_orientation = camera_orientation\n",
        "\n",
        "\n",
        "  def add_feature(self, feature, feature_corners):\n",
        "    self.features.append((feature, feature_corners))\n",
        "\n",
        "#Map represent the map of statuses and feaures, they are contained in lists\n",
        "class Map:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.positions = []\n",
        "    self.features = []\n",
        "\n",
        "\n",
        "  def add_feature(self, feature):\n",
        "    self.features.append(feature)\n",
        "\n",
        "\n",
        "  def add_status(self, status):\n",
        "    self.positions.append(status)\n",
        "\n",
        "  def print(self):\n",
        "    print('number of features in map = ', len(self.features))\n",
        "    print('number of statuses in map = ', len(self.positions))\n",
        "    maxx = 0\n",
        "    maxy = 0\n",
        "    minx = 9999\n",
        "    miny = 9999\n",
        "    xf = []\n",
        "    yf = []\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for f in self.features:\n",
        "      a,b = f.space_coords\n",
        "\n",
        "      if a > maxx:\n",
        "        maxx = a\n",
        "      if b > maxy:\n",
        "        maxy = b\n",
        "      if a < minx:\n",
        "        minx = a\n",
        "      if b < miny:\n",
        "        miny = b\n",
        "\n",
        "      xf.append(a)\n",
        "      yf.append(b)\n",
        "\n",
        "    c,d = 0,0\n",
        "    for s in self.positions:\n",
        "      print('number of features visible from image ', s.image, ' = ', len(s.features))\n",
        "      a,b = s.camera_coords\n",
        "\n",
        "      print(np.sqrt((a-c)**2+(b-d)**2))\n",
        "\n",
        "      c = a\n",
        "      d = b\n",
        "\n",
        "      if a > maxx:\n",
        "        maxx = a\n",
        "      if b > maxy:\n",
        "        maxy = b\n",
        "      if a < minx:\n",
        "        minx = a\n",
        "      if b < miny:\n",
        "        miny = b\n",
        "\n",
        "      xs.append(a)\n",
        "      ys.append(b)\n",
        "\n",
        "    max = 0\n",
        "    min = 0\n",
        "    if maxx > maxy:\n",
        "      max = maxx\n",
        "    else:\n",
        "      max = maxy\n",
        "\n",
        "    if minx > miny:\n",
        "      min = minx\n",
        "    else:\n",
        "      min = miny\n",
        "\n",
        "    plt.plot(xs, ys, 'bo')\n",
        "    plt.plot(xf,yf,'ro')\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTWz0Xxb_4ie"
      },
      "outputs": [],
      "source": [
        "#Miscellaneous and auxiliaries\n",
        "\n",
        "#Used to remove ambiguous matches in 'confront scenes'\n",
        "def remove_same_point_correspondences(pts1, pts2):\n",
        "  dt = np.dtype(float,float)\n",
        "\n",
        "  f,g = np.unique(np.array(pts1, dtype=dt),return_counts= True, axis = 0)\n",
        "  h,l = np.unique(np.array(pts2, dtype=dt),return_counts= True, axis = 0)\n",
        "\n",
        "  f = [tuple(f[p]) for p in range(len(f)) if g[p] > 1]\n",
        "\n",
        "  h = [tuple(h[p]) for p in range(len(h)) if l[p] > 1]\n",
        "\n",
        "  pts1 = [pts1[p] for p in range(len(pts1)) if pts2[p] not in h]\n",
        "  pts2 = [pts2[p] for p in range(len(pts2)) if pts2[p] not in h]\n",
        "\n",
        "  pts2 = [pts2[p] for p in range(len(pts2)) if pts1[p] not in f]\n",
        "  pts1 = [pts1[p] for p in range(len(pts1)) if pts1[p] not in f]\n",
        "\n",
        "  return pts1, pts2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBk88blt_Cnm"
      },
      "outputs": [],
      "source": [
        "#Operations on single image\n",
        "\n",
        "#returns the coords of the corners of the box created by the detector\n",
        "def retrieve_box_corners(img, description_path):\n",
        "  h,w = 0, 0\n",
        "  if len(img.shape) == 2:\n",
        "    h, w = img.shape\n",
        "  else:\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "  res = []\n",
        "  file = open(description_path, \"r\")\n",
        "  line = file.readline()\n",
        "\n",
        "  while line != \"\":\n",
        "    data = line.split()\n",
        "    x_center = float(data[1])\n",
        "    y_center = float(data[2])\n",
        "    width = float(data[3])\n",
        "    height = float(data[4])\n",
        "\n",
        "    x_center *= w\n",
        "    y_center *= h\n",
        "    width *= w\n",
        "    height *= h\n",
        "\n",
        "    corner1 = (round(x_center - width/2), (round(y_center - height/2)))\n",
        "    corner2 = (round(x_center + width/2), (round(y_center - height/2)))\n",
        "    corner3 = (round(x_center - width/2), (round(y_center + height/2)))\n",
        "    corner4 = (round(x_center + width/2), (round(y_center + height/2)))\n",
        "\n",
        "    figure = [corner1, corner2, corner3, corner4]\n",
        "    res.append(figure)\n",
        "\n",
        "    line = file.readline()\n",
        "  file.close()\n",
        "  return res\n",
        "\n",
        "\n",
        "#returns the sizes of the box created by the detector\n",
        "def retrieve_box_sizes(img, description_path):\n",
        "  h,w = 0, 0\n",
        "  if len(img.shape) == 2:\n",
        "    h, w = img.shape\n",
        "  else:\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "  res = []\n",
        "  file = open(description_path, \"r\")\n",
        "  line = file.readline()\n",
        "\n",
        "  while line != \"\":\n",
        "    data = line.split()\n",
        "    x_center = float(data[1])\n",
        "    y_center = float(data[2])\n",
        "    width = float(data[3])\n",
        "    height = float(data[4])\n",
        "\n",
        "    x_center *= w\n",
        "    y_center *= h\n",
        "    width *= w\n",
        "    height *= h\n",
        "\n",
        "    figure = [x_center, y_center, width, height]\n",
        "    res.append(figure)\n",
        "\n",
        "    line = file.readline()\n",
        "  file.close()\n",
        "  return res\n",
        "\n",
        "\n",
        "#returns only keypoints fuond inside the box found by the detector\n",
        "def is_point_in_border(point, corners, x_extension = 0, y_extension = 0):\n",
        "  min_x = corners[0][0] - x_extension\n",
        "  max_x = corners[1][0] + x_extension\n",
        "  min_y = corners[0][1] - y_extension\n",
        "  max_y = corners[2][1] + y_extension\n",
        "\n",
        "  x = point.pt[0]\n",
        "  y = point.pt[1]\n",
        "\n",
        "  if x >= min_x and x <= max_x and y >= min_y and y <= max_y:\n",
        "    return True\n",
        "\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9FyJrWN_HBl"
      },
      "outputs": [],
      "source": [
        "#Main functions for feature matching and Sfm\n",
        "\n",
        "#calibrates camrea, returns intrinsic matrix\n",
        "def calibrate_camera(chessboard_path, suffix='.jpg'):#from opencv tutorial website\n",
        "  chessboard_path += '/*' + suffix\n",
        "\n",
        "  # termination criteria\n",
        "  criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "  # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
        "  objp = np.zeros((6*7,3), np.float32)\n",
        "  objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
        "\n",
        "  # Arrays to store object points and image points from all the images.\n",
        "  objpoints = [] # 3d point in real world space\n",
        "  imgpoints = [] # 2d points in image plane.\n",
        "\n",
        "  images = glob.glob(chessboard_path)\n",
        "\n",
        "  for fname in images:\n",
        "    img = cv.imread(fname)\n",
        "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    # Find the chess board corners\n",
        "    ret, corners = cv.findChessboardCorners(gray, (7,6), None)\n",
        "    # If found, add object points, image points (after refining them)\n",
        "    if ret == True:\n",
        "      objpoints.append(objp)\n",
        "\n",
        "      corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
        "      imgpoints.append(corners2)\n",
        "\n",
        "      #cv.drawChessboardCorners(img, (7,6), corners2, ret)\n",
        "      #plt.imshow(img)\n",
        "\n",
        "  ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
        "  return mtx, dist, rvecs, tvecs\n",
        "\n",
        "\n",
        "#uses SIFT to detect keypoints\n",
        "def detect_keypoints(img):\n",
        "  # Initiate SIFT detector\n",
        "  sift = cv.SIFT_create()\n",
        "\n",
        "  # find the keypoints and descriptors with SIFT\n",
        "  kps, des = sift.detectAndCompute(img,None)\n",
        "\n",
        "  return kps, des\n",
        "\n",
        "\n",
        "#removes keypoints outside a box\n",
        "def filter_keypoints(kps, des, corners):\n",
        "\n",
        "  ret_kps = []\n",
        "  ret_des = []\n",
        "  for i in range(len(kps)):\n",
        "    if is_point_in_border(kps[i], corners, 200, 200):\n",
        "      ret_kps.append(kps[i])\n",
        "      ret_des.append(des[i])\n",
        "\n",
        "  return tuple(ret_kps), np.array(ret_des)\n",
        "\n",
        "\n",
        "#confronts features in images, two images with many matchings have high chance of portaiyng same streetlamp\n",
        "def confront_scenes(kp1, des1, kp2, des2):\n",
        "\n",
        "  #FLANN matches\n",
        "  FLANN_INDEX_KDTREE = 1\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
        "  search_params = dict(checks = 50)\n",
        "\n",
        "  flann = cv.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "  matches = flann.knnMatch(des1,des2,k=2)\n",
        "\n",
        "   # Apply ratio test\n",
        "  pts1, pts2 = [],[]\n",
        "  for m,n in matches:\n",
        "    if m.distance < 0.75*n.distance:\n",
        "      pts1.append(kp1[m.queryIdx].pt)\n",
        "      pts2.append(kp2[m.trainIdx].pt)\n",
        "\n",
        "  #remove dupliacates\n",
        "  pts1,pts2 = remove_same_point_correspondences(pts1, pts2)\n",
        "\n",
        "  pts1,pts2 = np.float32(pts1), np.float32(pts2)\n",
        "\n",
        "  if len(pts1) < 5:#cannot apply RANSAC\n",
        "    return [],[]\n",
        "\n",
        "  #apply Ransac\n",
        "  model, inliers = ransac(\n",
        "      (pts1,pts2),\n",
        "      AffineTransform, min_samples=4,\n",
        "      residual_threshold=8, max_trials=10000\n",
        "  )\n",
        "\n",
        "  n_inliers = np.sum(inliers)\n",
        "  print(n_inliers)\n",
        "  if n_inliers is None or n_inliers == 0:\n",
        "    return [], []\n",
        "\n",
        "  inlier_pts1 = [cv.KeyPoint(point[0], point[1], 1) for point in pts1[inliers]]\n",
        "  inlier_pts2 = [cv.KeyPoint(point[0], point[1], 1) for point in pts2[inliers]]\n",
        "\n",
        "  placeholder_matches = [cv.DMatch(idx, idx, 1) for idx in range(n_inliers)]\n",
        "\n",
        "  pts1 = np.float32([ inlier_pts1[m.queryIdx].pt for m in placeholder_matches ]).reshape(-1, 2)\n",
        "  pts2 = np.float32([ inlier_pts2[m.trainIdx].pt for m in placeholder_matches ]).reshape(-1, 2)\n",
        "\n",
        "  return pts1, pts2\n",
        "\n",
        "#retrieves the Essential matrix E and uses it to fintÃ¬d rotation matrix R and translation vector t\n",
        "def get_rotation_and_translation(intrinsic_matrix, pts1, pts2):\n",
        "\n",
        "  pts1 = np.int32(pts1)\n",
        "  pts2 = np.int32(pts2)\n",
        "  E, mask = cv.findEssentialMat(pts1, pts2, intrinsic_matrix,cv.RANSAC)\n",
        "\n",
        "  #recover R and t and\n",
        "  #check for cheirality\n",
        "  retval, R, t, mask = cv.recoverPose(E, pts1, pts2, intrinsic_matrix, mask)\n",
        "  return R,t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSBNNG0B_VHV"
      },
      "outputs": [],
      "source": [
        "#Just Geometry\n",
        "\n",
        "#given R, t and distances, returns where the camera is in relation to previous position at (0,0) looking towards increasing y\n",
        "def get_camera_position(R, t, distance_of_cameras,direction_of_first_camera = np.array([0,0,1])):\n",
        "  #where it is\n",
        "  c = -R.T @ t\n",
        "  c = np.array([c[0],c[2]])\n",
        "  c = (c/np.linalg.norm(c))*distance_of_cameras\n",
        "  c = np.reshape(c,(2,))\n",
        "  #where it's looking\n",
        "  obj = R.T @ direction_of_first_camera\n",
        "  obj = np.array([obj[0],obj[2]])\n",
        "  #normalize vector because it's just for direction\n",
        "  obj = (obj/np.linalg.norm(obj))\n",
        "\n",
        "  return c, obj\n",
        "\n",
        "#takes coordinates with camera at (0,0) turns them into map coordinates\n",
        "#all inputs are vectors which represent a direction\n",
        "def get_coordinates_in_map(translation, camera_orientation, real_coordinates, real_orientation):\n",
        "\n",
        "  translation, camera_orientation, real_coordinates, real_orientation = np.array(translation), np.array(camera_orientation), np.array(real_coordinates), np.array(real_orientation)\n",
        "\n",
        "  x = real_orientation[0]\n",
        "  y = real_orientation[1]\n",
        "\n",
        "  rot = None\n",
        "\n",
        "  if y != 0:\n",
        "    real_angle = np.arctan(x/y)\n",
        "    rot = np.array([[np.cos(real_angle),-np.sin(real_angle)],[np.sin(real_angle),np.cos(real_angle)]])\n",
        "  else:\n",
        "    if x > 0:\n",
        "      rot = np.array([[0,-1],[1,0]])\n",
        "    else:\n",
        "      rot = np.array([[0,-1],[1,0]])\n",
        "\n",
        "  real_translation = translation @ rot\n",
        "\n",
        "  real_translation[0] += real_coordinates[0]\n",
        "  real_translation[1] += real_coordinates[1]\n",
        "\n",
        "  real_camera_orientation =  camera_orientation @ rot\n",
        "\n",
        "  return real_translation, real_camera_orientation\n",
        "\n",
        "\n",
        "#given two points returns a third on same line at a distance from the second point\n",
        "def next_point_in_line(pt1, pt2, distance):\n",
        "  x = pt1[0]-pt2[0]\n",
        "  y = pt1[1]-pt2[1]\n",
        "\n",
        "  signx = 1\n",
        "  signy = 1\n",
        "\n",
        "  if x < 0:\n",
        "    signx = -1\n",
        "  if y < 0:\n",
        "    signy = -1\n",
        "\n",
        "  if x == 0.0:\n",
        "    if y < 0:\n",
        "      x = 0\n",
        "      y = -distance\n",
        "    else:\n",
        "      x = 0\n",
        "      y = distance\n",
        "  else:\n",
        "    angle = np.arctan(y/x)\n",
        "    x = np.cos(angle)*distance\n",
        "    y = np.sin(angle)*distance\n",
        "\n",
        "  if signx*x < 0:\n",
        "    x *= -1\n",
        "  if signy*y < 0:\n",
        "    y *= -1\n",
        "\n",
        "  pt3 = (x+pt1[0],y+pt1[1])\n",
        "  return pt3\n",
        "\n",
        "#returns coordinates of feature for a camera at (0,0) facing direction_of_camera\n",
        "def get_feature_coords(distance_from_camera, offset_from_camera, direction_of_camera):\n",
        "\n",
        "  np.array(direction_of_camera)\n",
        "  rot = np.array([[0,-1],[1,0]])\n",
        "  direction_of_offset = direction_of_camera @ rot\n",
        "\n",
        "  distance = direction_of_camera/np.linalg.norm(direction_of_camera) * distance_from_camera\n",
        "  offset = direction_of_offset/np.linalg.norm(direction_of_offset) * offset_from_camera\n",
        "\n",
        "  return distance + offset\n",
        "\n",
        "\n",
        "#to find position of object\n",
        "def triangle_similarity(intrinsic_matrix, pixel_height, real_height, center):\n",
        "  fx = intrinsic_matrix[0][0]\n",
        "  fy = intrinsic_matrix[1][1]\n",
        "  cx = intrinsic_matrix[0][2]\n",
        "  cy = intrinsic_matrix[1][2]\n",
        "  x = center[0]\n",
        "  y = center[1]\n",
        "  distance = (real_height * fy) / pixel_height\n",
        "  offset = ((x-cx)*distance) / fx\n",
        "  return distance, offset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWnndad5Kwdy"
      },
      "outputs": [],
      "source": [
        "#aux functions to create_map\n",
        "\n",
        "#used to check if a feature is present in a previous status\n",
        "def confront_feature_and_status(intrinsic_matrix, prev_status, new_status, corners2, feature_position, position, discarted_features):\n",
        "  matches_in_same_image={}\n",
        "\n",
        "  imgname1 = prev_status.image\n",
        "  imgname2 = new_status.image\n",
        "\n",
        "  for other_f in prev_status.features:\n",
        "\n",
        "    corners1 = other_f[1]\n",
        "    f = other_f[0]\n",
        "\n",
        "    if f not in discarted_features:\n",
        "\n",
        "      kp1,des1 = filter_keypoints(prev_status.kps, prev_status.des, corners1)\n",
        "      kp2, des2 = filter_keypoints(new_status.kps, new_status.des, corners2)\n",
        "      pts1,pts2 = confront_scenes(kp1, des1, kp2, des2 )\n",
        "\n",
        "      if len(pts1) <= 5:\n",
        "        print('no match between:')\n",
        "        print(imgname1,':',corners1)\n",
        "        print(imgname2,':',corners2)\n",
        "        discarted_features.append(f)\n",
        "\n",
        "      else:\n",
        "\n",
        "        matches_in_same_image[f] = corners1\n",
        "\n",
        "    else:\n",
        "      print('saving some time')\n",
        "\n",
        "  best_feature = None\n",
        "  best_distance = 9999\n",
        "  c = None\n",
        "\n",
        "  #filters all found matches leaving only the closest one\n",
        "  for f_match in matches_in_same_image:\n",
        "    pf_old = f_match.space_coords\n",
        "\n",
        "    distance = np.linalg.norm(np.array(pf_old) - np.array(feature_position))\n",
        "    if distance < best_distance:\n",
        "      best_feature = f_match\n",
        "      best_distance = distance\n",
        "      c = matches_in_same_image[f_match]\n",
        "\n",
        "  if best_feature is not None:\n",
        "    print('found match between:')\n",
        "    print(imgname1,':', c)\n",
        "    print(imgname2,':',corners2)\n",
        "\n",
        "  return best_feature\n",
        "\n",
        "#given the positions found for the same streetlamp finds a better estimate\n",
        "def get_better_position_estimate(plausible_positions):\n",
        "  #for now it is just the average\n",
        "  res = [0,0]\n",
        "  n = len(plausible_positions)\n",
        "  for xy in plausible_positions:\n",
        "    res[0]+=xy[0]\n",
        "    res[1]+=xy[1]\n",
        "\n",
        "  res[0]/=n\n",
        "  res[1]/=n\n",
        "  return tuple(plausible_positions.pop())#tuple(res)\n",
        "\n",
        "def get_better_orientation_estimate(plausible_orientations):\n",
        "  #for now it is just the average\n",
        "  res = [0,0]\n",
        "  n = len(plausible_orientations)\n",
        "  for xy in plausible_orientations:\n",
        "    res[0]+=xy[0]\n",
        "    res[1]+=xy[1]\n",
        "\n",
        "  res[0]/=n\n",
        "  res[1]/=n\n",
        "  return tuple(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T89BKKPS1CvL"
      },
      "outputs": [],
      "source": [
        "#this function creates the map\n",
        "def create_map3(labels_path, imgs_path, distance, street_lamp_height, intrinsic_matrix, steps = 99, suffix = '.jpg'):\n",
        "\n",
        "  steps_count = 0\n",
        "  map = Map()\n",
        "  curr_position = (0,0)\n",
        "  prev_position = (0,0)\n",
        "  prev_orientation = (0,1)\n",
        "  prev_status = None\n",
        "  d = 0\n",
        "\n",
        "  #reading the files\n",
        "  length1 = len(imgs_path)\n",
        "  length2 = len(labels_path)\n",
        "  images = glob.glob(imgs_path + \"/*\" + suffix)\n",
        "  images.sort()\n",
        "\n",
        "  labels = glob.glob(labels_path + \"/*.txt\")\n",
        "  labels.sort()\n",
        "\n",
        "  #it also work if the image set is in the reversed order\n",
        "  #images.reverse()\n",
        "  #labels.reverse()\n",
        "\n",
        "  #scans one image at a a time\n",
        "  for imgname in images:\n",
        "\n",
        "    #check condition to stop early\n",
        "    print(steps_count)\n",
        "    if steps_count >= steps:\n",
        "      return map\n",
        "    steps_count +=1\n",
        "\n",
        "    #for each image searches its labels\n",
        "    name = imgname[length1 + 1: (len(imgname)- len(suffix))]\n",
        "    if len(labels) > 0:\n",
        "      text = labels[0]\n",
        "      text = text[length2 + 1: (len(text)- len('.txt'))]\n",
        "    else:\n",
        "      text = ''\n",
        "\n",
        "    lbls = ''\n",
        "\n",
        "    if name == text :\n",
        "      lbls = labels.pop(0)\n",
        "\n",
        "    #reads image and finds keypoints\n",
        "    curr_img = cv.imread(imgname, cv.IMREAD_GRAYSCALE)\n",
        "    kps, des = detect_keypoints(curr_img)\n",
        "    #print(len(kps))\n",
        "\n",
        "    if prev_status is not None:#if not first image in sequence\n",
        "\n",
        "      #extracts distance from previous image\n",
        "      if isinstance(distance, list):\n",
        "        d = distance.pop(0)\n",
        "      else:\n",
        "        d = distance\n",
        "\n",
        "      #confronts images to find matches\n",
        "      pts1, pts2 = confront_scenes(prev_status.kps, prev_status.des, kps, des)\n",
        "\n",
        "      #print('found:', len(pts1),'points')\n",
        "\n",
        "      if len(pts1) <= 5:\n",
        "        print('not enough points found')\n",
        "        #not enough points, it has to guess position...\n",
        "        new_position = next_point_in_line(curr_position, prev_position, d)\n",
        "        new_orientation = prev_orientation\n",
        "\n",
        "        prev_position = curr_position\n",
        "        curr_position = new_position\n",
        "        prev_orientation = new_orientation\n",
        "\n",
        "      else:\n",
        "        #finds where the camera is\n",
        "        R,t = get_rotation_and_translation(intrinsic_matrix, pts1,pts2)\n",
        "        c,ori = get_camera_position(R,t,d)\n",
        "\n",
        "        #this is the position of the camera\n",
        "        new_position, new_orientation = get_coordinates_in_map(c, ori, curr_position, prev_orientation)\n",
        "\n",
        "        prev_position = curr_position\n",
        "        curr_position = new_position\n",
        "        prev_orientation = new_orientation\n",
        "\n",
        "      #creates new status with the found position\n",
        "      new_status = Status(imgname, kps, des, curr_position, prev_orientation)\n",
        "\n",
        "      if lbls != '':#there are streetlamps in image\n",
        "        curr_features_sizes = retrieve_box_sizes(curr_img, lbls)\n",
        "        curr_features_corners = retrieve_box_corners(curr_img, lbls)\n",
        "\n",
        "        #in case two features in the same image match the same one in another image\n",
        "        ambiguous_matches = {}\n",
        "        #list of new features\n",
        "        left_out_features = []\n",
        "\n",
        "        #for every lamp\n",
        "        for f in curr_features_sizes:\n",
        "\n",
        "          #calculates where lamp is\n",
        "          height = f[3]\n",
        "          center = (f[0], f[1])\n",
        "          corners = curr_features_corners.pop(0)\n",
        "\n",
        "          distance_from_camera, offset_from_camera = triangle_similarity(intrinsic_matrix, height, street_lamp_height, center)\n",
        "          print('object is far away:', distance_from_camera)\n",
        "          if distance_from_camera > 30:\n",
        "            print('ignoring objects too far away')\n",
        "            continue\n",
        "\n",
        "          #this is the position of the feature\n",
        "          pf_new = get_feature_coords(distance_from_camera, offset_from_camera, prev_orientation)\n",
        "          pf_new[0] += curr_position[0]\n",
        "          pf_new[1] += curr_position[1]\n",
        "\n",
        "          #scan all previous images to find if the feature is alredy present\n",
        "          found_match = False\n",
        "          discarted_features = []\n",
        "          for s in reversed(map.positions):\n",
        "\n",
        "            f_matched = confront_feature_and_status(intrinsic_matrix, s, new_status, corners, pf_new, curr_position, discarted_features)\n",
        "            if f_matched is not None:\n",
        "              old_coords = f_matched.space_coords\n",
        "\n",
        "              error = np.linalg.norm(np.array(old_coords) - np.array(pf_new))\n",
        "              print('error:', error)\n",
        "              #if the lamp is too far away from where it should be likely the match is wrong\n",
        "              if error < 10:\n",
        "                #if this is the only one that matches\n",
        "                if f_matched not in ambiguous_matches:\n",
        "\n",
        "                  ambiguous_matches[f_matched] = (pf_new, corners)\n",
        "                  found_match = True\n",
        "                  break\n",
        "\n",
        "                else:\n",
        "                  pf_other = ambiguous_matches[f_matched][0]\n",
        "                  corners_other = ambiguous_matches[f_matched][1]\n",
        "                  other_error = np.linalg.norm(np.array(old_coords) - np.array(pf_other))\n",
        "\n",
        "                  #if one had already matched only keeps the closest\n",
        "                  if error < other_error:\n",
        "                    print('corrected ambiguity')\n",
        "                    ambiguous_matches[f_matched] = (pf_new, corners)\n",
        "                    left_out_features.append((pf_other, corners_other))\n",
        "                    found_match = True\n",
        "                    break\n",
        "\n",
        "                  else:\n",
        "                    print('match discarted for ambiguity')\n",
        "\n",
        "              else:\n",
        "                print('distance of matched features is above threshold, match is likely wrong')\n",
        "\n",
        "          if not found_match:\n",
        "            #new feature...\n",
        "            print('found new feature')\n",
        "            left_out_features.append((pf_new, corners))\n",
        "\n",
        "        #finds a more accurate position for old features\n",
        "        for m in ambiguous_matches:\n",
        "          old_coords = m.space_coords\n",
        "          pf_new = ambiguous_matches[m][0]\n",
        "          corners_new = ambiguous_matches[m][1]\n",
        "          new_coords = get_better_position_estimate([old_coords,pf_new])\n",
        "          m.space_coords = new_coords\n",
        "          m.add_image(imgname, corners_new)\n",
        "          new_status.add_feature(m, corners_new)\n",
        "\n",
        "        #inserts new features in map\n",
        "        for f in left_out_features:\n",
        "          f_new = Feature(imgname, f[1], f[0])\n",
        "          new_status.add_feature(f_new, f[1])\n",
        "          map.add_feature(f_new)\n",
        "\n",
        "      #adds image in map\n",
        "      map.add_status(new_status)\n",
        "      prev_status = new_status\n",
        "\n",
        "    else:#this is first image\n",
        "      #starts at (0,0)\n",
        "      new_status = Status(imgname, kps, des, curr_position, prev_orientation)\n",
        "\n",
        "      if lbls != '':#there are features\n",
        "\n",
        "        curr_features_sizes = retrieve_box_sizes(curr_img, lbls)\n",
        "        curr_features_corners = retrieve_box_corners(curr_img, lbls)\n",
        "\n",
        "        for f in curr_features_sizes:\n",
        "          height = f[3]\n",
        "          center = (f[0], f[1])\n",
        "          corners = curr_features_corners.pop(0)\n",
        "          #finds where features are\n",
        "          distance_from_camera, offset_from_camera = triangle_similarity(intrinsic_matrix, height, 7.5, center)\n",
        "          print('object is far away:', distance_from_camera)\n",
        "          if distance_from_camera > 50:\n",
        "            print('ignoring objects too far away')\n",
        "            continue\n",
        "\n",
        "          #all features are in this case new feature...\n",
        "          print('found new feature')\n",
        "          pf_new = get_feature_coords(distance_from_camera, offset_from_camera, prev_orientation)\n",
        "          pf_new[0] += curr_position[0]\n",
        "          pf_new[1] += curr_position[1]\n",
        "          f_new = Feature(imgname, corners, pf_new)\n",
        "          new_status.add_feature(f_new, corners)\n",
        "          map.add_feature(f_new)\n",
        "\n",
        "      map.add_status(new_status)\n",
        "      prev_status = new_status\n",
        "\n",
        "  return map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtcAXDwg6Y0U"
      },
      "outputs": [],
      "source": [
        "#to detect lamps must use the detect.py program from terminal\n",
        "#it is situated inside the directory yolov9\n",
        "#make sure the --save-txt instruction is present, it will save the labels in the yolov9 directory, they're needed in the next cell\n",
        "%cd /content/'path to yolov9'/yolov9\n",
        "!python detect.py --weights /content/'path to yolov9'/yolov9/runs/train/exp3/weights/best.pt --conf 0.40 --source /content/'path to the streetlamp pictures' --device cpu --save-txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18uyLilPda4s"
      },
      "outputs": [],
      "source": [
        "#if the intrinsic matrix is not known it is necessary to calibrate first, insert the path to the photos of checkerboard pattern and their file extension (png, jpg, JPG etc.)\n",
        "#sometimes calibration can require a large amount of photos, if it does not work at first probably it needs more pictures\n",
        "mtx, _, _, _ = calibrate_camera('here goes the path of the directory containing chessboard photos', suffix = 'here goes the file extension')\n",
        "print(mtx)\n",
        "\n",
        "#in order to create the map it needs the path to the labels and the images, the distance between each picture (suggested 1m), the height of the streetlamps (may or may not be 7), and the matrix\n",
        "map = create_map3('here goes the path to the labels generated by the detection', 'here goes the path to the images taken (the ones without the bounding box)', 1, 7, mtx, suffix = '.jpg')\n",
        "#shows the map\n",
        "map.print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GlUbKXB5beE3eKksAZKsKdmTidVf4kSg",
      "authorship_tag": "ABX9TyPOEjS07S/iwE+9jBaSqRWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}